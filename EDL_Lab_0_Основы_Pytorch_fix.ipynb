{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-4ruFNf5KOv"
      },
      "source": [
        "\n",
        "#  Основы PyTorch\n",
        "\n",
        "## Введение\n",
        "\n",
        "Материал предназначен для краткого введения в основы PyTorch и подготовки для написания собственных нейронных сетей.\n",
        "\n",
        "PyTorch — это платформа машинного обучения с открытым исходным кодом, которая позволяет вам писать собственные нейронные сети и эффективно их оптимизировать. Однако PyTorch — не единственная платформа такого рода. Существующие альтернативы PyTorch — TensorFlow, JAX.\n",
        "\n",
        "Здесь будут показаны основы, необходимые для выполнения практических занятий, нпозволяющие понять как PyTorch работает «под капотом».\n",
        "\n",
        "Мы будем использовать набор стандартных библиотек, которые часто используются в проектах машинного обучения.\n",
        "\n",
        "чек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXQrEUpz43qn"
      },
      "outputs": [],
      "source": [
        "## Стандартные библиотеки\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "## Импорты для графиков\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg', 'pdf') # For export\n",
        "from matplotlib.colors import to_rgba\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "## библиотека для отображени прогресс-бара\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXGxQr9x5I6I"
      },
      "source": [
        "# Основы\n",
        "\n",
        "Начнем с основных концепций PyTorch. В качестве предварительного условия рекомендуется ознакомиться с пакетом `numpy`, поскольку большинство фреймворков машинного обучения основаны на очень похожих концепциях.\n",
        "\n",
        "Если вы еще не знакомы с numpy, не волнуйтесь: вот [руководство](https://numpy.org/devdocs/user/quickstart.html), с которым стоит ознакомиться.\n",
        "\n",
        "Итак, начнем с импорта PyTorch. Пакет называется `torch` и основан на оригинальном фреймворке Torch.\n",
        "\n",
        "Проверяем его версию:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-C-vMT16JHwX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(\"Using torch\", torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6P1gkgKO5H3"
      },
      "source": [
        "Как и в любом фреймворке машинного обучения, PyTorch предоставляет стохастические функции, такие как генерация случайных чисел. Классической практикой является настройка воспроизводимости вашего кода с одинаковыми случайными числами. Вот почему мы установили параметр `seed` ниже."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6EaRWR1PJhd"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42) # Setting the seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hzc_P2q8QIPX"
      },
      "source": [
        "### Тензоры\n",
        "\n",
        "Тензоры PyTorch — объекты, эквивалентные массивам Numpy, с добавлением поддержки ускорения при помощи графического процессора.\n",
        "Название «тензор» — это обобщение уже известных вам понятий. Например, вектор — это одномерный тензор, а матрица — двумерный тензор. При работе с нейронными сетями мы будем использовать тензоры различной размерности.\n",
        "\n",
        "Наиболее распространенные функции, которые вы знаете из numpy, также можно использовать с тензорами. На самом деле, поскольку массивы numpy очень похожи на тензоры, мы можем преобразовать большинство тензоров в массивы numpy (и обратно).\n",
        "\n",
        "#### Инициализация\n",
        "\n",
        "Давайте сначала начнем с рассмотрения различных способов создания тензора. Существует множество возможных вариантов, самый простой — вызвать `torch.Tensor`, передав требуемую форму в качестве входного аргумента:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbZd_KHQQrGp"
      },
      "outputs": [],
      "source": [
        "x = torch.Tensor(2, 3, 4)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoC5csskQtz2"
      },
      "source": [
        "Функция `torch.Tensor` выделяет память для нужного тензора, но повторно использует любые значения, которые уже были в памяти. Чтобы напрямую присвоить значения тензору во время инициализации, существует множество альтернатив, в том числе:\n",
        "\n",
        "* `torch.zeros`: Создает тензор, заполненный нулями.\n",
        "* `torch.ones`: Создает тензор, заполненный единицами.\n",
        "* `torch.rand`: Создает тензор со случайными значениями, равномерно выбранными от 0 до 1.\n",
        "* `torch.randn`: Создает тензор со случайными значениями, выбранными из нормального распределения со средним значением 0 и дисперсией 1.\n",
        "* `torch.arange`: Создает тензор, содержащий значения $N,N+1,N+2,...,M$\n",
        "* `torch.Tensor` (входной список): создает тензор из предоставленных вами элементов списка."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0Qu0OIiRO91"
      },
      "outputs": [],
      "source": [
        "# Create a tensor from a (nested) list\n",
        "x = torch.Tensor([[1, 2], [3, 4]])\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNfC8zEjRRHu"
      },
      "outputs": [],
      "source": [
        "# Create a tensor with random values between 0 and 1 with the shape [2, 3, 4]\n",
        "x = torch.rand(2, 3, 4)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASa0G7GIRXcG"
      },
      "source": [
        "Получить форму тензора можно так же, как в numpy (`x.shape`), или используя метод `.size`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Drr3Q_uMRRAd"
      },
      "outputs": [],
      "source": [
        "shape = x.shape\n",
        "print(\"Shape:\", x.shape)\n",
        "\n",
        "size = x.size()\n",
        "print(\"Size:\", size)\n",
        "\n",
        "dim1, dim2, dim3 = x.size()\n",
        "print(\"Size:\", dim1, dim2, dim3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgQUudeIUNrG"
      },
      "source": [
        "#### Тензор в Numpy и Numpy в Тензор\n",
        "\n",
        "Тензоры можно преобразовать в массивы numpy, а массивы numpy обратно в тензоры. Чтобы преобразовать массив numpy в тензор, мы можем использовать функцию torch.from_numpy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dt6sGQYUSI-"
      },
      "outputs": [],
      "source": [
        "np_arr = np.array([[1, 2], [3, 4]])\n",
        "tensor = torch.from_numpy(np_arr)\n",
        "\n",
        "print(\"Numpy array:\", np_arr)\n",
        "print(\"PyTorch tensor:\", tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFNGoM4GUYVn"
      },
      "source": [
        "Чтобы преобразовать тензор PyTorch обратно в массив numpy, мы можем использовать функцию `.numpy()` для тензоров:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JT1fOJNuUaH-"
      },
      "outputs": [],
      "source": [
        "tensor = torch.arange(4)\n",
        "np_arr = tensor.numpy()\n",
        "\n",
        "print(\"PyTorch tensor:\", tensor)\n",
        "print(\"Numpy array:\", np_arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh0nR_fFUf1L"
      },
      "source": [
        "Преобразование тензоров в numpy требует, чтобы тензор находился на ЦПУ, а не на графическом процессоре.\n",
        "Если у вас есть тензор на графическом процессоре, вам необходимо заранее вызвать .cpu() для тензора. Следовательно, получится строка вида `np_arr = tensor.cpu().numpy()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQBuftd7UlCK"
      },
      "source": [
        "#### Операции\n",
        "\n",
        "Большинство операций, существующих в numpy, также существуют и в PyTorch. Полный список операций можно найти в [документации PyTorch](https://pytorch.org/docs/stable/tensors.html#), но здесь мы рассмотрим наиболее важные из них.\n",
        "\n",
        "Самая простая операция — сложить два тензора:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ho5ZMm-PUtBW"
      },
      "outputs": [],
      "source": [
        "x1 = torch.rand(2, 3)\n",
        "x2 = torch.rand(2, 3)\n",
        "y = x1 + x2\n",
        "\n",
        "print(\"X1\", x1)\n",
        "print(\"X2\", x2)\n",
        "print(\"Y\", y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhuqGx24Uz49"
      },
      "source": [
        "Вызов `x1 + x2` создает новый тензор, содержащий сумму двух входных данных. Однако мы также можем использовать операции на месте, которые применяются непосредственно к памяти тензора. Поэтому мы изменяем значения `x2` без возможности повторного доступа к значениям `x2` перед операцией. Пример показан ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ncxf7r8U503"
      },
      "outputs": [],
      "source": [
        "x1 = torch.rand(2, 3)\n",
        "x2 = torch.rand(2, 3)\n",
        "print(\"X1 (before)\", x1)\n",
        "print(\"X2 (before)\", x2)\n",
        "\n",
        "x2.add_(x1)\n",
        "print(\"X1 (after)\", x1)\n",
        "print(\"X2 (after)\", x2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATME5bm9U-jO"
      },
      "source": [
        "Операции на месте обычно отмечаются постфиксом подчеркивания (например, «add_» вместо «add»).\n",
        "\n",
        "Другая распространенная операция направлена на изменение формы тензора. Тензор размера (2,3) можно реорганизовать в любую другую форму с тем же количеством элементов (например, тензор размера (6) или (3,2),...). В PyTorch этo операция  `view`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HP7KvOdRVAvm"
      },
      "outputs": [],
      "source": [
        "x = torch.arange(6)\n",
        "print(\"X\", x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPO97Ug9VCfO"
      },
      "outputs": [],
      "source": [
        "x = x.view(2, 3)\n",
        "print(\"X\", x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSqaBVIdVFmm"
      },
      "outputs": [],
      "source": [
        "x = x.permute(1, 0) # Переставляем размерность\n",
        "print(\"X\", x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoFvXdVwVNh-"
      },
      "source": [
        "Другие часто используемые операции включают умножение матриц, которые необходимы для нейронных сетей. Например, у нас есть входной вектор $\\mathbf{x}$, который преобразуется с использованием весовой матрицы $\\mathbf{W}$. Существует множество способов и функций для умножения матриц, некоторые из которых:\n",
        "\n",
        "* `torch.matmul`: матричное произведение двух тензоров, где конкретное поведение зависит от размеров. Если оба входа являются матрицами (двумерными тензорами), он выполняет стандартное матричное произведение. Для входных данных более высокой размерности функция поддерживает broadcasting ( термин, описывающий способность фреймворка производить арифметические операции над массивами различной размерности) (подробности см. в [документации](https://pytorch.org/docs/stable/generated/torch.matmul.html?highlight=matmul#torch.matmul)). Произведение может записано как `a @ b`, аналогично numpy.\n",
        "* `torch.mm`: выполняет матричное произведение двух матриц, но не поддерживает broadcasting (см. [документацию](https://pytorch.org/docs/stable/generated/torch.mm.html?highlight=torch%20mm#torch.mm))\n",
        "* `torch.bmm`: вычисляет произведение с доп.  размерностью. Если первый тензор $T$ имеет форму ($b\\times n\\times m$), а второй тензор $R$ ($b\\times m\\times p$), выходной $O$ имеет форму ( $b\\times n\\times p$) и вычисляется путём $b$ матричного умножения подматриц $T$ и $R$: $O_i = T_i @ R_i$\n",
        "* `torch.einsum`: выполняет матричные умножения и другие операции (т.е. суммы произведений), используя конв-ю Эйнштейна о суммировании.\n",
        "\n",
        "Чаще в обихо идет torch.matmul или torch.bmm. Попробуем умножить матрицу с помощью torch.matmul ниже."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aqVEUOefsaK"
      },
      "outputs": [],
      "source": [
        "x = torch.arange(6)\n",
        "x = x.view(2, 3)\n",
        "print(\"X\", x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3RpaqtMfvE2"
      },
      "outputs": [],
      "source": [
        "W = torch.arange(9).view(3, 3) # We can also stack multiple operations in a single line\n",
        "print(\"W\", W)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RnymM97fwiO"
      },
      "outputs": [],
      "source": [
        "h = torch.matmul(x, W) # Verify the result by calculating it by hand too!\n",
        "print(\"h\", h)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-m6_CQqEfy89"
      },
      "source": [
        "#### Индексирование\n",
        "\n",
        "Часто возникают ситуации, когда нам нужно выделить часть тензора. Индексирование работает так же, как и в numpy, поэтому давайте попробуем:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7QRy_dyijP1"
      },
      "outputs": [],
      "source": [
        "x = torch.arange(12).view(3, 4)\n",
        "print(\"X\", x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnsSco96il_u"
      },
      "outputs": [],
      "source": [
        "print(x[:, 1])   # второй столбец"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjZvy-5RiniN"
      },
      "outputs": [],
      "source": [
        "print(x[0])      # первая строка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQhqeVgyipDN"
      },
      "outputs": [],
      "source": [
        "print(x[:2, -1]) # первые две строки, последний столбец"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yz-ahQdriqbV"
      },
      "outputs": [],
      "source": [
        "print(x[1:3, :]) # две строки посередине"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNCP-3pjngHH"
      },
      "source": [
        "### Динамический вычислительный граф и  обратное распространение ошибки\n",
        "\n",
        "Одна из основных причин использования PyTorch в проектах глубокого обучения заключается в том, что мы можем автоматически получать **градиенты/производные** функций, которые мы определяем. Если мы используем матрицы весов в нашей функции, которую хотим изучить, то они называются **параметрами** или просто **весами**.\n",
        "\n",
        "Если бы наша нейронная сеть выдавала одно скалярное значение, мы бы говорили о взятии **производной**, но чаще будет **множество** выходных переменных («значений»); в этом случае мы говорим о **градиентах**. Это более общий термин.\n",
        "\n",
        "Учитывая входные данные $\\mathbf{x}$, мы определяем нашу функцию,  выполняя различные операции над  этими входными данными, обычно путем умножения на весовые матрицы и сложения с так называемыми векторами смещения (bias).\n",
        "Производя вычисления на входными данными, мы автоматически создаем **вычислительный граф**. В графе показано, как получается результат на основе входных данных.\n",
        "PyTorch — это **фреймворк, определяемый при запуске**; т.е. что мы можем просто выполнять свои манипуляции, а PyTorch будет отслеживать этот граф для нас. Таким образом, мы попутно создаем динамический граф вычислений.\n",
        "\n",
        "Первое, что нам нужно сделать, это указать, какие тензоры требуют градиентов. По умолчанию, когда мы создаем тензор, он не требует градиентов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RO4lcZOWnkVJ"
      },
      "outputs": [],
      "source": [
        "x = torch.ones((3,))\n",
        "print(x.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG1CS8REnpw-"
      },
      "source": [
        "Мы можем изменить это для существующего тензора, используя функцию `requires_grad_()` (подчеркивание указывает, что это in-place операция). Альтернативно, при создании тензора вы можете передать аргумент `requires_grad=True` большинству инициализаторов, которые мы видели выше."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DChDs5MFnvlu"
      },
      "outputs": [],
      "source": [
        "x.requires_grad_(True)\n",
        "print(x.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oV6uXhsHnzFu"
      },
      "source": [
        "Чтобы ознакомиться с концепцией графа вычислений, мы создадим его для следующей функции:\n",
        "\n",
        "$$y = \\frac{1}{\\ell(x)}\\sum_i \\left[(x_i + 2)^2 + 3\\right],$$\n",
        "\n",
        "где мы используем $\\ell(x)$ для обозначения количества элементов в $x$. Другими словами, здесь мы берем среднее значение по операции внутри суммы. Вы можете представить, что $x$ — это наши параметры, и мы хотим оптимизировать (максимизировать или минимизировать) выходные данные $y$. Для этого мы хотим получить градиенты $\\partial y/\\partial \\mathbf{x}$. В нашем примере мы будем использовать $\\mathbf{x}=[0,1,2]$ в качестве входных данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-z0zM6logqe"
      },
      "outputs": [],
      "source": [
        "x = torch.arange(3, dtype=torch.float32, requires_grad=True) # Только тензоры с плавающей запятой могут иметь градиенты\n",
        "print(\"X\", x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEHWCxHWojz-"
      },
      "source": [
        "Теперь построим граф вычислений шаг за шагом. Вы можете объединить несколько операций в одной строке, но здесь мы разделим их, чтобы лучше понять, как каждая операция добавляется в граф вычислений."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFHRF4RwoqpO"
      },
      "outputs": [],
      "source": [
        "a = x + 2\n",
        "b = a ** 2\n",
        "c = b + 3\n",
        "y = c.mean()\n",
        "print(\"Y\", y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wp4VbaxMoq_W"
      },
      "source": [
        "Используя приведенные выше утверждения, мы создали граф вычислений, похожий на рисунок ниже:\n",
        "\n",
        "<center style=\"width: 100%\"><img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/pytorch_computation_graph.svg?raw=1\" width=\"200px \"></center>\n",
        "\n",
        "Мы вычисляем $a$ на основе входных данных $x$ и константы $2$, $b$ — это $a$ в квадрате и так далее. Эта визуализация — абстракция зависимостей между входными и выходными данными примененных нами операций.\n",
        "Каждый узел графа вычислений автоматически определил функцию для расчета градиентов относительно своих входных данных, `grad_fn`. Вы можете увидеть это, когда мы вывели выходной тензор $y$. Вот почему граф вычислений обычно визуализируется в обратном направлении (стрелки указывают от результата к входным данным). Мы можем выполнить обратное распространение ошибки на графе вычислений, вызвав функцию `backward()` на последнем выходе, которая эффективно вычисляет градиенты для каждого тензора, имеющего свойство `require_grad=True`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge3T2OiMnrwu"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfhXxlGQo-U3"
      },
      "outputs": [],
      "source": [
        "y.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQEnVWrlpDJw"
      },
      "source": [
        "`x.grad` теперь будет содержать градиент $\\partial y/ \\partial \\mathcal{x}$, и этот градиент показывает, как изменение $\\mathbf{x}$ повлияет на выходной сигнал $y$ при текущем входном $ \\mathbf{x}=[0,1,2]$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZTZfq-ZpxRW"
      },
      "outputs": [],
      "source": [
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux4kaQEMpz5-"
      },
      "source": [
        "*Мы* также можем проверить эти градиенты вручную. Мы будем рассчитывать градиенты, используя цепное правило, так же, по аналогии с PyTorch:\n",
        "\n",
        "\n",
        "$$\\frac{\\partial y}{\\partial x_i} = \\frac{\\partial y}{\\partial c_i}\\frac{\\partial c_i}{\\partial b_i}\\frac{\\partial b_i}{\\partial a_i}\\frac{\\partial a_i}{\\partial x_i}$$\n",
        "\n",
        "\n",
        "Обратите внимание, что мы упростили это уравнение до индексной записи и использовали тот факт, что все операции, кроме среднего, не объединяют элементы в тензоре. Частные производные:\n",
        "\n",
        "\n",
        "$$\n",
        "\\frac{\\partial a_i}{\\partial x_i} = 1,\\hspace{1cm}\n",
        "\\frac{\\partial b_i}{\\partial a_i} = 2\\cdot a_i\\hspace{1cm}\n",
        "\\frac{\\partial c_i}{\\partial b_i} = 1\\hspace{1cm}\n",
        "\\frac{\\partial y}{\\partial c_i} = \\frac{1}{3}\n",
        "$$\n",
        "\n",
        "Следовательно, если на входе $\\mathbf{x}=[0,1,2]$, наши градиенты будут $\\partial y/\\partial \\mathbf{x}=[4/3,2,8/3]$ . Предыдущая ячейка кода должна была вывести тот же результат."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxBO5KF-qFCe"
      },
      "source": [
        "### Поддержка графического процессора\n",
        "\n",
        "В PyTorch по умолчанию есть поддержка вычислений на графических процессорах.\n",
        "\n",
        "Графические процессоры могут ускорить обучение модели в 100 раз, что критически важно для больших нейронных сетей. PyTorch реализует множество функций для поддержки графических процессоров (в основном NVIDIA благодаря библиотекам [CUDA](https://developer.nvidia.com/cuda-zone) и [cuDNN](https://developer.nvidia.com/cudnn).\n",
        "\n",
        "Проверим, достуен ли графический процессор:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2eFYgZ5rlFO"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJSAGk-SrqnB"
      },
      "source": [
        "Теперь давайте создадим тензор и отправим его на устройство:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4Ju6Tezrws2"
      },
      "outputs": [],
      "source": [
        "x = torch.zeros(2, 3)\n",
        "x = x.to(device)\n",
        "print(\"X\", x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY5XCQZKr3X-"
      },
      "source": [
        "Если  есть графический процессор, видим атрибут `device='cuda:0'`, рядом с тензором.\n",
        "Ноль указывает, что это нулевое графическое устройство на вашем компьютере.\n",
        "PyTorch также поддерживает системы с несколькими графическими процессорами, но это понадобится вам только в том случае, если у вас есть очень большие сети для обучения (если интересно, см. [документацию PyTorch](https://pytorch.org/docs/stable/distributed.html#distributed-basics)).\n",
        "Также можем сравнить время выполнения умножения большой матрицы на процессоре с операцией на графическом процессоре:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPNKz6K5r_x_"
      },
      "outputs": [],
      "source": [
        "x = torch.randn(5000, 5000)\n",
        "\n",
        "## CPU\n",
        "start_time = time.time()\n",
        "_ = torch.matmul(x, x)\n",
        "end_time = time.time()\n",
        "print(f\"CPU time: {(end_time - start_time):6.5f}s\")\n",
        "\n",
        "## GPU\n",
        "x = x.to(device)\n",
        "_ = torch.matmul(x, x)\n",
        "# Первая операция по «прожигу» графического процессора\n",
        "# CUDA асинхронна, поэтому нам нужно использовать разные функции синхронизации\n",
        "\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "start.record()\n",
        "_ = torch.matmul(x, x)\n",
        "end.record()\n",
        "torch.cuda.synchronize()  # Ждем, пока все завершится на графическом процессоре\n",
        "print(f\"GPU time: {0.001 * start.elapsed_time(end):6.5f}s\")  # Milliseconds to seconds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTyU8CUbsEQ2"
      },
      "source": [
        "В зависимости от размера операции и процессора/графического процессора в вашей системе ускорение этой операции может быть более чем в 50 раз. Поскольку операции matmul очень распространены в нейронных сетях, мы уже видим большую выгоду от обучения нейросетей на графическом процессоре. Оценка времени здесь может быть относительно зашумленной, поскольку мы не запускали ее несколько раз.\n",
        "\n",
        "При генерации случайных чисел начальное число между процессором и графическим процессором не синхронизируется. Следовательно, нам нужно установить начальное число на графическом процессоре отдельно, чтобы обеспечить воспроизводимый код. Обратите внимание: из-за разных архитектур графических процессоров выполнение одного и того же кода на разных графических процессорах не гарантирует одинаковых случайных чисел. Тем не менее, мы не хотим, чтобы наш код выдавал разные выходные данные каждый раз, когда мы запускаем его на одном и том же оборудовании. Следовательно, мы также устанавливаем seed на графический процессор:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bS8fSGaCsLt2"
      },
      "outputs": [],
      "source": [
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# Кроме того, некоторые операции на графическом процессоре реализованы стохастически для повышения эффективности.\n",
        "# Мы хотим гарантировать, что все операции детерминированы на графическом процессоре (если он используется) для воспроизводимости.\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbZrSHpbs2Ie"
      },
      "source": [
        "## Обучение на примере: непрерывное исключающее ИЛИ\n",
        "\n",
        "Если мы хотим построить нейронную сеть в PyTorch, мы могли бы указать все наши параметры (весовые матрицы, векторы смещения) с помощью `Tensors` (с `requires_grad=True`), попросить PyTorch вычислить градиенты, а затем настроить параметры. Но все может быстро стать громоздким, если у нас много параметров. В PyTorch есть пакет `torch.nn`, который делает построение нейронных сетей более удобным.\n",
        "\n",
        "Мы представим библиотеки и все дополнительные части, которые могут вам понадобиться для обучения нейронной сети в PyTorch, используя простой классификатор на хорошо известном примере: XOR. Учитывая два двоичных входа $x_1$ и $x_2$, прогнозируемая метка равна $1$, если один из $x_1$ или $x_2$ равен $1$, а другой — $0$, или метка $0$ во всех остальных случаях. Пример показателен тем, что один нейрон, то есть линейный классификатор, не может обучиться этой простой функции.\n",
        "\n",
        "Следовательно, мы узнаем, как построить небольшую нейронную сеть, которая сможет аппроксимировать эту функцию.\n",
        "\n",
        "Чтобы сделать задачу немного интереснее, мы переместим исключающее ИЛИ в непрерывное пространство и введем некоторый гауссов шум на двоичные входы. Желаемое нами разделение набора данных XOR может выглядеть следующим образом:\n",
        "\n",
        "<center style=\"width: 100%\"><img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/continuous_xor.svg?raw=1\" width=\"350px\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhnwbyOawn2H"
      },
      "source": [
        "### Модель\n",
        "\n",
        "Пакет `torch.nn` определяет ряд полезных классов, таких как слои линейных сетей, функции активации, функции потерь и т. д. Полный список можно найти [здесь](https://pytorch.org/docs/stable/nn.html). Мы импортируем его ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FM1I_xsYs1xW"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nySlgTrFw6q_"
      },
      "source": [
        "Помимо `torch.nn` существует также `torch.nn.functional`. Он содержит функции, которые используются на сетевых уровнях. В этом отличие от `torch.nn`, который определяет их как `nn.Modules` (подробнее об этом ниже), а `Torch.nn` фактически использует множество функций `Torch.nn.functional`. Следовательно, функциональный пакет полезен во многих ситуациях, поэтому мы также импортируем его сюда."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ek66Euf1xQ02"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxuPecXPyWK2"
      },
      "source": [
        "#### nn.Модуль\n",
        "\n",
        "В PyTorch нейронная сеть состоит из модулей. Модули могут содержать другие модули, и нейронная сеть также считается модулем. Базовый шаблон модуля выглядит следующим образом:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOAUbYdnyZ0O"
      },
      "outputs": [],
      "source": [
        "class MyModule(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "      # Функция для выполнения вычисления прямого прохода модуля.\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdopnvMU3sqO"
      },
      "source": [
        "В функции `forward` происходит вычисление модуля, и она выполняется при вызове модуля (`nn = MyModule(); nn(x)`). В функции `init` мы обычно инициализируем параметры модуля, используя `nn.Parameter` или определяя другие модули, которые используются в прямой функции. Обратный проход (`backward`) выполняется автоматически, но при желании его также можно переопределить.\n",
        "\n",
        "#### Простой классификатор\n",
        "Теперь мы можем использовать предопределенные модули в пакете `torch.nn` и определить нашу собственную небольшую нейронную сеть. Мы будем использовать минимальную сеть с входным слоем, одним скрытым слоем с `tanh` в качестве функции активации и выходным слоем. Другими словами, наши сети должны выглядеть примерно так:\n",
        "\n",
        "<center width=\"100%\"><img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/small_neural_network.svg?raw=1\" width=\"300px\"> </center>\n",
        "\n",
        "Входные нейроны показаны синим цветом и представляют координаты $x_1$ и $x_2$ точки данных. Скрытые нейроны, включая активацию `tanh`, показаны белым, а выходной нейрон - красным.\n",
        "В PyTorch мы можем определить это следующим образом:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnUjySZq4DiW"
      },
      "outputs": [],
      "source": [
        "class SimpleClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
        "        super().__init__()\n",
        "        # Инициализируем модули для построения сети\n",
        "        self.linear1 = nn.Linear(num_inputs, num_hidden)\n",
        "        self.act_fn = nn.Tanh()\n",
        "        self.linear2 = nn.Linear(num_hidden, num_outputs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Вычисление прямого прохода\n",
        "        x = self.linear1(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Icw7UTRm51U3"
      },
      "source": [
        "Для примеров в этом блокноте мы будем использовать крошечную нейронную сеть с двумя входными нейронами и четырьмя скрытыми нейронами. При выполнении бинарной классификации мы будем использовать один выходной нейрон. Обратите внимание, что мы пока не применяем сигмоидальную функцию к выходным данным. Это связано с тем, что функции потерь более эффективны и точны для расчета на исходных выходных данных, а не тех что были обработаны при помощи сигмоиды. Подробную причину мы обсудим ниже."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OeG9jvm54PF"
      },
      "outputs": [],
      "source": [
        "model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1)\n",
        "# При печати модуля отображаются все его подмодули\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s7h8wqp58rW"
      },
      "source": [
        "При отображении структуры модели выводятся все содержащиеся в ней подмодули. Параметры модуля можно получить, используя его функции `parameters()` или `named_parameters()`, чтобы получить имя для каждого объекта параметра. Для нашей небольшой нейронной сети у нас есть следующие параметры:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iQqkOYU5_Dl"
      },
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"Parameter {name}, shape {param.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXOZBMsNghMe"
      },
      "source": [
        "Каждый линейный слой имеет весовую матрицу формы `[output, input]` и bias формы `[output]`. Функция активации `tanh` не имеет параметров. Обратите внимание, что параметры регистрируются только для объектов `nn.Module`, которые являются прямыми атрибутами объекта, то есть `self.a = ...`. Если вы определяете список модулей, их параметры не регистрируются для внешнего модуля и могут вызвать некоторые проблемы при попытке оптимизировать модуль. Существуют альтернативы: `nn.ModuleList`, `nn.ModuleDict` и `nn.Sequential`, которые позволяют  иметь разные структуры данных модулей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUX2Aiscg9_k"
      },
      "source": [
        "### Данные\n",
        "\n",
        "PyTorch также предоставляет несколько функций для эффективной загрузки данных обучения и тестирования, которые обобщены в пакете `torch.utils.data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtCUWghdhNSk"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLVErv7NhTBk"
      },
      "source": [
        "Пакет данных определяет два класса, которые являются стандартным интерфейсом для обработки данных в PyTorch: `data.Dataset` и `data.DataLoader`. Класс набора данных обеспечивает единый интерфейс для доступа к данным обучения/тестирования, а загрузчик данных обеспечивает эффективную загрузку и объединение точек данных из набора данных в пакеты во время обучения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9IPMBez3A_X"
      },
      "source": [
        "#### Класс набора данных\n",
        "\n",
        "Класс набора данных естественным образом обобщает основные функции набора данных. Чтобы определить набор данных в PyTorch, мы просто указываем две функции: `__getitem__` и `__len__`. Функция get-item должна вернуть $i$-ю точку данных в наборе данных, а функция len возвращает размер набора данных. Для набора данных XOR мы можем определить класс набора данных следующим образом:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLIMHCcc3Uvo"
      },
      "outputs": [],
      "source": [
        "class XORDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, size, std=0.1):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            size - Number of data points we want to generate\n",
        "            std - Standard deviation of the noise (see generate_continuous_xor function)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.size = size\n",
        "        self.std = std\n",
        "        self.generate_continuous_xor()\n",
        "\n",
        "    def generate_continuous_xor(self):\n",
        "         # Каждая точка в наборе данных XOR имеет две переменные, x и y, которые могут иметь значение 0 или 1.\n",
        "         # Метка (label) представляет собой их комбинацию XOR, т. е. 1, если только x или только y равен 1, а другой равен 0.\n",
        "         # Если x=y, метка равна 0.\n",
        "        data = torch.randint(low=0, high=2, size=(self.size, 2), dtype=torch.float32)\n",
        "        label = (data.sum(dim=1) == 1).to(torch.long)\n",
        "        # Чтобы немного усложнить задачу, мы добавляем к точкам немного гауссова шума.\n",
        "        data += self.std * torch.randn(data.shape)\n",
        "\n",
        "        self.data = data\n",
        "        self.label = label\n",
        "\n",
        "    def __len__(self):\n",
        "        # Количество имеющихся у нас точек данных. Альтернативно self.data.shape[0] или self.label.shape[0]\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Возвращаем idx-ю точку датасета\n",
        "        # Если нужно вернуть несколько объектов (точку данных и метку), мы можем вернуть их в виде кортежа\n",
        "        data_point = self.data[idx]\n",
        "        data_label = self.label[idx]\n",
        "        return data_point, data_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbr4jWUY3bEo"
      },
      "source": [
        "Давайте попробуем создать такой датасет и проверить его:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqiNjnUI3exP"
      },
      "outputs": [],
      "source": [
        "dataset = XORDataset(size=200)\n",
        "print(\"Size of dataset:\", len(dataset))\n",
        "print(\"Data point 0:\", dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlI7f51D3jG3"
      },
      "source": [
        "Визуализируем образцы из набора ниже."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhtWOHtS3nmQ"
      },
      "outputs": [],
      "source": [
        "def visualize_samples(data, label):\n",
        "    if isinstance(data, torch.Tensor):\n",
        "        data = data.cpu().numpy()\n",
        "    if isinstance(label, torch.Tensor):\n",
        "        label = label.cpu().numpy()\n",
        "    data_0 = data[label == 0]\n",
        "    data_1 = data[label == 1]\n",
        "\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.scatter(data_0[:,0], data_0[:,1], edgecolor=\"#333\", label=\"Class 0\")\n",
        "    plt.scatter(data_1[:,0], data_1[:,1], edgecolor=\"#333\", label=\"Class 1\")\n",
        "    plt.title(\"Dataset samples\")\n",
        "    plt.ylabel(r\"$x_2$\")\n",
        "    plt.xlabel(r\"$x_1$\")\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXJKEDqX3pS4"
      },
      "outputs": [],
      "source": [
        "visualize_samples(dataset.data, dataset.label)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0rNw2FH3wnQ"
      },
      "source": [
        "#### Класс загрузчика данных\n",
        "\n",
        "Класс `torch.utils.data.DataLoader` представляет собой итераор Python по набору данных с поддержкой автоматической пакетной обработки, многопроцессной загрузки данных и т.д. Загрузчик данных взаимодействует с набором данных с помощью функции `__getitem__` и компонует свои выходные данные в виде тензоров по первому измерению, формируя батч.\n",
        "В отличие от класса набора данных, нам обычно не нужно определять собственный класс загрузчика данных, а можно просто создать его объект с набором данных в качестве входных данных. Кроме того, мы можем настроить наш загрузчик данных со следующими входными аргументами (только некоторые из них, полный список см. [здесь](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)) :\n",
        "\n",
        "* `batch_size`: количество образцов, которые необходимо сложить в одну партию.\n",
        "* `shuffle`: если True, данные возвращаются в случайном порядке. Это важно во время обучения для соблюдения стохастичности.\n",
        "* `num_workers`: количество подпроцессов, используемых для загрузки данных. Значение по умолчанию, 0, означает, что данные будут загружены в основном процессе, что может замедлить обучение в случае наборов данных, где загрузка  занимает значительное время (например, большие изображения).\n",
        "Для малых наборов данных, таких как наш, 0 рабочих обычно работают быстрее.\n",
        "* `pin_memory`: Если установлено значение True, загрузчик данных скопирует Tensor в закрепленную память CUDA, прежде чем вернуть их. Это позволит сэкономить  время для больших датасетов на графических процессорах. Обычно это хорошая практика для использования обучающего набора, но не обязательно для валидации или тестирования с целью экономии памяти на графическом процессоре.\n",
        "* `drop_last`: Если установлено значение True, последний пакет удаляется, если он меньше указанного размера пакета. Это происходит, когда размер набора данных не кратен размеру пакета. Потенциально полезно во время обучения поддерживать постоянный размер батча.\n",
        "\n",
        "Давайте создадим простой загрузчик данных ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oJD4JxC32QI"
      },
      "outputs": [],
      "source": [
        "data_loader = data.DataLoader(dataset, batch_size=8, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7L7rlt-35z4"
      },
      "outputs": [],
      "source": [
        "# next(iter(...)) catches the first batch of the data loader\n",
        "# If shuffle is True, this will return a different batch every time we run this cell\n",
        "# For iterating over the whole dataset, we can simple use \"for batch in data_loader: ...\"\n",
        "data_inputs, data_labels = next(iter(data_loader))\n",
        "\n",
        "# The shape of the outputs are [batch_size, d_1,...,d_N] where d_1,...,d_N are the\n",
        "# dimensions of the data point returned from the dataset class\n",
        "print(\"Data inputs\", data_inputs.shape, \"\\n\", data_inputs)\n",
        "print(\"Data labels\", data_labels.shape, \"\\n\", data_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvlNW1kV4GHR"
      },
      "source": [
        "### Оптимизация\n",
        "\n",
        " В ходе обучения мы выполним следующие действия:\n",
        "\n",
        "1. Получение пакета (батч/пачка) из загрузчика данных\n",
        "2. Вычисление предсказаний модели для батча.\n",
        "3. Вычисление функции потерь (лосса) на основе разницы между полученным предсказанием и исходными метками.\n",
        "4. Обратное распространение ошибки: расчет градиентов для каждого параметра с учетом потерь.\n",
        "5. Обновление параметров модели.\n",
        "\n",
        "Мы увидели, как можно выполнить шаги 1, 2 и 4 в PyTorch. Теперь мы рассмотрим шаги 3 и 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2TSHDna4Uzo"
      },
      "source": [
        "#### Функция потерь\n",
        "\n",
        "Мы можем рассчитать потери для пакета, просто выполнив несколько тензорных операций, поскольку они автоматически добавляются в граф вычислений. Например, для двоичной классификации мы можем использовать двоичную перекрестную энтропию (Binary Cross Entropy BCE , которая определяется следующим образом:\n",
        "\n",
        "\n",
        "$$\\mathcal{L}_{BCE} = -\\sum_i \\left[ y_i \\log x_i + (1 - y_i) \\log (1 - x_i) \\right]$$\n",
        "\n",
        "где $y$ — наши метки, а $x$ — наши предсказания, оба в диапазоне $[0,1]$. PyTorch предоставляет список предопределенных функций потерь, которые мы можем использовать (полный список см. [здесь](https://pytorch.org/docs/stable/nn.html#loss-functions). Например, для BCE PyTorch имеет два модуля: `nn.BCELoss`(), `nn.BCEWithLogitsLoss()`. В то время как `nn.BCELoss` ожидает, что входные данные $x$ будут находиться в диапазоне $[0,1]$, т.е. выходные данные сигмоида, `nn.BCEWithLogitsLoss` объединяет слой с сигмоидой и BCE в одном классе. Эта версия численно более стабильна, чем использование простой сигмоиды с последующей потерей BCE из-за логарифмов, применяемых в функции потерь. Следовательно, рекомендуется использовать функции потерь, применяемые к «логитам», где это возможно (не забудьте в этом случае не применять сигмовидную форму к выходным данным модели!). Поэтому для нашей модели, определенной выше, мы используем модуль nn.BCEWithLogitsLoss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lS8mcgqQp0m"
      },
      "outputs": [],
      "source": [
        "loss_module = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79ey88Q2Pv9i"
      },
      "source": [
        "#### Стохастический градиентный спуск\n",
        "\n",
        "Для обновления параметров PyTorch предоставляет пакет `torch.optim`, в котором реализовано большинство популярных оптимизаторов. В данной работе будем использовать типовой стохастический градиентный спуск: `torch.optim.SGD`.\n",
        "\n",
        "Стохастический градиентный спуск обновляет параметры, умножая градиенты на небольшую константу, называемую скоростью обучения, и вычитая их из параметров/весов  минимизируя целевую функцию потерь. Поэтому мы потихоньку движемся в направлении минимизации потерь.\n",
        "\n",
        "Значение скорости обучения по умолчанию для такой небольшой сети, как наша, составляет 0,1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjHDgU-n4aBH"
      },
      "outputs": [],
      "source": [
        "# Входные параметры оптимизатора - параметры модели\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElnYEPQn4e5I"
      },
      "source": [
        "Оптимизатор предоставляет две полезные функции: `optimizer.step()` и `optimizer.zero_grad()`. Функция step обновляет параметры на основе градиентов, как описано выше. Функция optimizer.zero_grad() устанавливает градиенты всех параметров в ноль.\n",
        "Хотя на первый взгляд эта функция кажется менее актуальной, она является важным предварительным шагом перед выполнением обратного распространения ошибки. Если мы вызовем функцию `backward` при потере, в то время как градиенты параметров не равны нулю по сравнению с предыдущим пакетом, новые градиенты фактически будут добавлены к предыдущим, а не перезапишут их. Это сделано потому, что параметр может встречаться в графе вычислений несколько раз, и в этом случае нам нужно суммировать градиенты, а не заменять их. Следовательно,необхоимо вызвать `optimizer.zero_grad()` перед расчетом градиентов батча."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx_Xmg446XlZ"
      },
      "source": [
        "### Обучение\n",
        "\n",
        "Наконец, мы готовы обучать нашу модель. В качестве первого шага мы создаем немного больший набор данных и указываем загрузчик данных с большим размером пакета."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWYu08i76g-g"
      },
      "outputs": [],
      "source": [
        "train_dataset = XORDataset(size=2500)\n",
        "train_data_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEQNZw0H62gg"
      },
      "source": [
        "Теперь мы можем написать небольшую обучающую функцию.\n",
        "Помните наши пять шагов: загрузка батча, получение предсказаний, подсчет потерь, обратное распространение ошибки и обновление. Кроме того, нам необходимо передать все данные и параметры модели на выбранное нами устройство (графический процессор, если доступен). Для нашей примитивной нейронной сети передача данных в графический процессор на самом деле занимает гораздо больше времени, чем мы могли бы сэкономить, выполняя операцию на GPU. Для больших сетей время связи значительно меньше фактического времени работы, поэтому в этих случаях графический процессор имеет решающее значение. Тем не менее, для практики мы передадим данные в графический процессор."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQ2b1Ix165DY"
      },
      "outputs": [],
      "source": [
        "# Отправляем модель на GPU\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHmCi5Jn7HIY"
      },
      "source": [
        "Переводим модель в режим обучения. Это делается путем вызова `model.train()`. Существуют определенные модули, которым во время обучения необходимо выполнять действия, отличные чем во время тестирования (например, BatchNorm и Dropout), и мы можем переключаться между ними с помощью `model.train()` и `model.eval()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1uYvR-A7MaQ"
      },
      "outputs": [],
      "source": [
        "def train_model(model, optimizer, data_loader, loss_module, num_epochs=100):\n",
        "    # Переводим в режим обучения\n",
        "    model.train()\n",
        "\n",
        "    # Цикл обучения\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        for data_inputs, data_labels in data_loader:\n",
        "\n",
        "            ## Шаг 1: Отправим входные данные на устройство (если используем GPU)\n",
        "            data_inputs = data_inputs.to(device)\n",
        "            data_labels = data_labels.to(device)\n",
        "\n",
        "            ## Шаг 2: Запускаем модель на входных данных\n",
        "            preds = model(data_inputs)\n",
        "            preds = preds.squeeze(dim=1) # Выход здесь [Batch size, 1], нам необходимо [Batch size]\n",
        "\n",
        "            ## Шаг 3: Считаем лосс\n",
        "            loss = loss_module(preds, data_labels.float())\n",
        "\n",
        "            ## Шаг 4: Осуществляем обратное распространение\n",
        "            # Перед подсчетом градиентов зануляем\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            ## Шаг 5: Обновляем параметры\n",
        "            optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iw4n21Kh-b10"
      },
      "outputs": [],
      "source": [
        "train_model(model, optimizer, train_data_loader, loss_module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iin4ubWn6gcQ"
      },
      "source": [
        "#### Сохранение модели\n",
        "\n",
        "После завершения обучения модели мы сохраняем ее на диск, чтобы позже загрузить те же веса. Для этого мы извлекаем из модели так называемый `state_dict`, который содержит все обучаемые параметры.\n",
        "\n",
        "В нашем случае словарь содержит следующее:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dcttnfcn7dEJ"
      },
      "outputs": [],
      "source": [
        "state_dict = model.state_dict()\n",
        "print(state_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0YQRsXS7iGY"
      },
      "source": [
        "Чтобы загрузить словарь состояний используем `torch.save`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lkmhVUA7j7Q"
      },
      "outputs": [],
      "source": [
        "# torch.save(object, filename). Для filename может быть использованю любое расширение\n",
        "\n",
        "torch.save(state_dict, \"our_model.tar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAE15N367ocq"
      },
      "source": [
        "Чтобы загрузить модель из словаря состояния, мы используем функцию `torch.load` для загрузки с диска и функцию модуля `load_state_dict` для перезаписи наших параметров новыми значениями:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNcXdAda7sJ4"
      },
      "outputs": [],
      "source": [
        "# Грузим с диска\n",
        "state_dict = torch.load(\"our_model.tar\")\n",
        "\n",
        "# Создаем новую модель и загружаем состояние\n",
        "new_model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1)\n",
        "new_model.load_state_dict(state_dict)\n",
        "\n",
        "# Проверяем что параметры одинаковые\n",
        "print(\"Original model\\n\", model.state_dict())\n",
        "print(\"\\nLoaded model\\n\", new_model.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9kpjx6X7uAB"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        " Подробный туториал про сохранение и загрузку моделй можно почитать [здесь](https://pytorch.org/tutorials/beginner/saving_loading_models.html).\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W82IitDA887p"
      },
      "source": [
        "### Оценка\n",
        "\n",
        "После того как модель обучена, пришло время оценить ее тестовом наборе. Поскольку наш набор данных состоит из случайно сгенерированных точек данных, необходимо сначала создать тестовый набор с соответствующим загрузчиком данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXsOw7xB9KaI"
      },
      "outputs": [],
      "source": [
        "test_dataset = XORDataset(size=500)\n",
        "# drop_last -> false параметр указывающий на то что последный батч будет обработан несмотря на то что его размерность меньше 128\n",
        "test_data_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False, drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McO92eHA9OFA"
      },
      "source": [
        "В качестве метрики мы будем использовать точность, которая рассчитывается следующим образом:\n",
        "\n",
        "$$acc = \\frac{\\#\\text{правильные предсказания}}{\\#\\text{все прдсказания}} = \\frac{TP+TN}{TP+TN+FP+FN}$$\n",
        "\n",
        "где TP — истинно положительные результаты, TN — истинно отрицательные результаты, FP — ложноположительные результаты и FN — ложноотрицательные результаты.\n",
        "\n",
        "При оценке модели деактивируем граф вычислений, используя `with torch.no_grad(): ...`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOUyahqf9Ykg"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader):\n",
        "    model.eval() # Устанавливаем мадель в режим тестирования\n",
        "    true_preds, num_preds = 0., 0.\n",
        "\n",
        "    with torch.no_grad(): # Выключаем градиенты\n",
        "        for data_inputs, data_labels in data_loader:\n",
        "\n",
        "            data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)\n",
        "            preds = model(data_inputs)\n",
        "            preds = preds.squeeze(dim=1)\n",
        "            preds = torch.sigmoid(preds) # Нелинейность/Сигмоида для отображения в диапазон 0 1\n",
        "            pred_labels = (preds >= 0.5).long() # Бинаризация предсказаний в формат 0 и 1\n",
        "\n",
        "            # (true_preds=TP+TN, num_preds=TP+TN+FP+FN)\n",
        "            # Сохраняем предсказания для подсчета целевой метрики\n",
        "            true_preds += (pred_labels == data_labels).sum()\n",
        "            num_preds += data_labels.shape[0]\n",
        "\n",
        "    acc = true_preds / num_preds\n",
        "    print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kd0XO7dU9aKc"
      },
      "outputs": [],
      "source": [
        "eval_model(model, test_data_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t94kktZU9dbx"
      },
      "source": [
        "Если мы правильно обучили нашу модель, мы должны увидеть точность, близкую к 100%. Однако этот сценарий возможен только благодаря изначально простой задаче, и, к сожалению, на тестовых наборах более сложных задач результат редко бывает подобным."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3Yeu56E9fg5"
      },
      "source": [
        "#### Визуализация разделяющей поверхности\n",
        "\n",
        "Чтобы отобразить то, чему научилась наша модель, мы можем выполнить прогноз для каждой точки данных в диапазоне $[-0,5, 1,5]$ и визуализировать пердсказанный класс, как показано на примере рисунка в начале этого раздела.\n",
        "\n",
        "Это демонстрирует, построена разделяющая поверхность, и какие точки будут классифицироваться как $0$, а какие — как $1$.\n",
        "\n",
        "Таким образом, получаем фоновое изображение синего (класс 0) и оранжевого (класс 1) цвета."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_lcgrHc9i9w"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad() # декоратор, то же что и \"with torch.no_grad(): ...\" над функцией.\n",
        "def visualize_classification(model, data, label):\n",
        "    if isinstance(data, torch.Tensor):\n",
        "        data = data.cpu().numpy()\n",
        "    if isinstance(label, torch.Tensor):\n",
        "        label = label.cpu().numpy()\n",
        "    data_0 = data[label == 0]\n",
        "    data_1 = data[label == 1]\n",
        "\n",
        "    fig = plt.figure(figsize=(4,4), dpi=500)\n",
        "    plt.scatter(data_0[:,0], data_0[:,1], edgecolor=\"#333\", label=\"Class 0\")\n",
        "    plt.scatter(data_1[:,0], data_1[:,1], edgecolor=\"#333\", label=\"Class 1\")\n",
        "    plt.title(\"Dataset samples\")\n",
        "    plt.ylabel(r\"$x_2$\")\n",
        "    plt.xlabel(r\"$x_1$\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Используем все чему мы научились выше\n",
        "    model.to(device)\n",
        "    c0 = torch.Tensor(to_rgba(\"C0\")).to(device)\n",
        "    c1 = torch.Tensor(to_rgba(\"C1\")).to(device)\n",
        "    x1 = torch.arange(-0.5, 1.5, step=0.01, device=device)\n",
        "    x2 = torch.arange(-0.5, 1.5, step=0.01, device=device)\n",
        "    xx1, xx2 = torch.meshgrid(x1, x2, indexing='ij')  # Meshgrid функция как в  numpy\n",
        "    model_inputs = torch.stack([xx1, xx2], dim=-1)\n",
        "    preds = model(model_inputs)\n",
        "    preds = torch.sigmoid(preds)\n",
        "    output_image = (1 - preds) * c0[None,None] + preds * c1[None,None]\n",
        "    output_image = output_image.cpu().numpy()  # Конвертируем в numpy массив. Это работает только для тензоров на CPU, следовательно oтправляем на CPU\n",
        "    plt.imshow(output_image, origin='lower', extent=(-0.5, 1.5, -0.5, 1.5))\n",
        "    plt.grid(False)\n",
        "    return fig\n",
        "\n",
        "_ = visualize_classification(model, dataset.data, dataset.label)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu_tGsyF99CA"
      },
      "source": [
        "### Использование TensorBoard\n",
        "\n",
        "TensorBoard — это инструмент для логгирования и визуализации, использующийся для обучения моделей глубокого обучения. Хотя TensorBoard изначально был опубликован для TensorFlow, он также интегрирован в PyTorch, что позволяет нам легко его использовать.\n",
        "\n",
        "Импортируем соответствующие библиотеки ниже."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2koy8-r-z55"
      },
      "outputs": [],
      "source": [
        "# Импортируем TensorBoard logger из PyTorch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# загружаем расширение для Jupyter Notebook\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d-hFDxY-3Mh"
      },
      "source": [
        "Последняя строка необходима, если необходимо запустить TensorBoard непосредственно в Jupyter Notebook. В другом случае можно запустить TensorBoard из терминала.\n",
        "\n",
        "API TensorBoard PyTorch достаточно прост в использовании. Начиаем работу с создания нового объекта `writer = SummaryWriter(...)`, где указываем каталог, в котором должен быть сохранен файл журнала. С помощью этого объекта мы можем логгировать различные аспекты нашей модели, вызывая `writer.add_...`. Например, мы можем визуализировать график вычислений с помощью функции `Write.add_graph` или добавить скалярное значение, такое как лосс, с помощью `Writer.add_scalar`.\n",
        "\n",
        "Адаптируем нашу первоначальную функцию обучения, добавив ниже логгер TensorBoard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "it0ouphj-5J5"
      },
      "outputs": [],
      "source": [
        "def train_model_with_logger(model, optimizer, data_loader, loss_module, val_dataset, num_epochs=100, logging_dir='runs/our_experiment'):\n",
        "    # Создаем TB логгер\n",
        "    writer = SummaryWriter(logging_dir)\n",
        "    model_plotted = False\n",
        "\n",
        "    # Переводим модель в режим обучения\n",
        "    model.train()\n",
        "\n",
        "    # Цикл обучения\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        epoch_loss = 0.0\n",
        "        for data_inputs, data_labels in data_loader:\n",
        "\n",
        "            ## Шаг 1: Отправим входные данные на устройство (если используем GPU)\n",
        "            data_inputs = data_inputs.to(device)\n",
        "            data_labels = data_labels.to(device)\n",
        "\n",
        "            # Для первого батча визуализируем граф вычсисдений в TB\n",
        "            if not model_plotted:\n",
        "                writer.add_graph(model, data_inputs)\n",
        "                model_plotted = True\n",
        "\n",
        "            ## Шаг 2: Запускаем модель на входных данных\n",
        "            preds = model(data_inputs)\n",
        "            preds = preds.squeeze(dim=1) # Выход здесь [Batch size, 1], нам необходимо [Batch size]\n",
        "\n",
        "            ## Шаг 3: Вычисляем функцию потерь\n",
        "            loss = loss_module(preds, data_labels.float())\n",
        "\n",
        "            ## Шаг 4: Осуществляем обратный проход вычислений\n",
        "            # перед подстчетом градиентов мы должны убедиться что все они занулены\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            ## Шаг 5: Обновляем параметры\n",
        "            optimizer.step()\n",
        "\n",
        "            ## Шаг 6: Аккумулируем лосс\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        # Отправляем усредненное значение функции потерь в TB\n",
        "        epoch_loss /= len(data_loader)\n",
        "        writer.add_scalar('training_loss',\n",
        "                          epoch_loss,\n",
        "                          global_step = epoch + 1)\n",
        "\n",
        "\n",
        "        # Рендерим каждую 10ю эпоху\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            fig = visualize_classification(model, val_dataset.data, val_dataset.label)\n",
        "            writer.add_figure('predictions',\n",
        "                              fig,\n",
        "                              global_step = epoch + 1)\n",
        "\n",
        "    writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYzWkn___0m5"
      },
      "source": [
        "\n",
        "\n",
        "Используем этот способ чтобы обучить модель по аналогии, но в этот раз с новой моделью и оптимизатором."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPvaTjMQ_17Z"
      },
      "outputs": [],
      "source": [
        "model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1).to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "train_model_with_logger(model, optimizer, train_data_loader, loss_module, val_dataset=dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0aO1VqU_5aA"
      },
      "source": [
        "Файл TensorBoard в папке runs/our_experiment теперь содержит кривую потерь, график вычислений нашей сети и визуализацию полученных пердсказаний за определенное количество эпох.\n",
        "\n",
        "Чтобы запустить визуализацю TensorBoard, просто выполните следующую инструкцию:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBcIVwX5_8Gh"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir runs/our_experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMjr6_TA_-bC"
      },
      "source": [
        "\n",
        "\n",
        "Визуализации (в т.ч. с использованеим TensorBoard) могут помочь выявить возможные проблемы с вашей моделью и выявить такие ситуации, как переобучение.\n",
        "\n",
        "Вы также можете отслеживать ход обучения во время обучения модели, поскольку регистратор автоматически записывает все добавленное к нему в файл журнала."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17y6Nqxx2fgF"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RynZ3DZdM2nF"
      },
      "source": [
        "# Полезные ссылки\n",
        "\n",
        "1.   [DEEP LEARNING WITH PYTORCH: A 60 MINUTE BLITZ](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
        "\n",
        "\n",
        "2.   [Руководство TensorBoard](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}